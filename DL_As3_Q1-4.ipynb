{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11866425,"sourceType":"datasetVersion","datasetId":7456773}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport wandb\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom prettytable import PrettyTable\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:40.852689Z","iopub.execute_input":"2025-05-19T07:04:40.853138Z","iopub.status.idle":"2025-05-19T07:04:48.239939Z","shell.execute_reply.started":"2025-05-19T07:04:40.853115Z","shell.execute_reply":"2025-05-19T07:04:48.239049Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"os.environ['WANDB_API_KEY'] = 'paste your wandb.ai key here'\nwandb.login()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:48.241247Z","iopub.execute_input":"2025-05-19T07:04:48.241729Z","iopub.status.idle":"2025-05-19T07:04:54.544254Z","shell.execute_reply.started":"2025-05-19T07:04:48.241702Z","shell.execute_reply":"2025-05-19T07:04:54.543733Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malandandoor\u001b[0m (\u001b[33malandandoor-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"SOW_token = 0\nEOW_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.n_letters = 2 # Count SOW and EOW\n        self.letter2index = {}\n        self.letter2count = {}\n        self.index2letter = {0: \"0\", 1: \"1\"}\n\n    def addWord(self, word):\n        for ch in word:\n            self.addLetter(ch)\n\n    def addLetter(self, ch):\n        if ch not in self.letter2index:\n            self.letter2index[ch] = self.n_letters\n            self.letter2count[ch] = 1\n            self.index2letter[self.n_letters] = ch\n            self.n_letters += 1\n        else:\n            self.letter2count[ch] += 1\n\ninput_lang = Lang('eng')\noutput_lang = Lang('mal')\nx_train = pd.read_csv('/kaggle/input/malayalam/ml/lexicons/ml.translit.sampled.train.tsv', sep='\\t', header=None) #, nrows=1000)\nx_val = pd.read_csv('/kaggle/input/malayalam/ml/lexicons/ml.translit.sampled.dev.tsv', sep='\\t', header=None)\nx_test = pd.read_csv('/kaggle/input/malayalam/ml/lexicons/ml.translit.sampled.test.tsv', sep='\\t', header=None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.544899Z","iopub.execute_input":"2025-05-19T07:04:54.545282Z","iopub.status.idle":"2025-05-19T07:04:54.688098Z","shell.execute_reply.started":"2025-05-19T07:04:54.545259Z","shell.execute_reply":"2025-05-19T07:04:54.687474Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"MAX_LENGTH = 50\n\ndef indexesFromWord(lang, word):\n    return [lang.letter2index[ch] for ch in word]\n\ndef tensorFromWord(lang, word):\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOW_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef wordFromTensor(lang, tensor):\n    s = \"\"\n    for i in tensor:\n        if(i.item()==1):\n            break\n        s += lang.index2letter[i.item()] \n    return s\n\ndef get_dataloader(x, input_lang, output_lang, batch_size):\n    pairs = list(zip(x[1].values, x[0].values))  # Get list of (input, target) tuples\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for i, (inp, tgt) in enumerate(pairs):\n        if not isinstance(inp, str) or not isinstance(tgt, str):\n            continue  # skip malformed entries\n\n        input_lang.addWord(inp)\n        output_lang.addWord(tgt)\n        inp_ids = indexesFromWord(input_lang, inp)\n        tgt_ids = indexesFromWord(output_lang, tgt)\n        inp_ids.append(EOW_token)\n        tgt_ids.append(EOW_token)\n        input_ids[i, :len(inp_ids)] = inp_ids\n        target_ids[i, :len(tgt_ids)] = tgt_ids\n\n    data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                         torch.LongTensor(target_ids).to(device))\n    sampler = RandomSampler(data)\n    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.689512Z","iopub.execute_input":"2025-05-19T07:04:54.690111Z","iopub.status.idle":"2025-05-19T07:04:54.697320Z","shell.execute_reply.started":"2025-05-19T07:04:54.690090Z","shell.execute_reply":"2025-05-19T07:04:54.696759Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, config, input_size):\n        super(EncoderRNN, self).__init__()\n        \n        self.bidirectional = False\n            \n        self.embedding = nn.Embedding(input_size, config.inp_embed_size)\n        self.algo = algorithms[config.cell_type](config.inp_embed_size, config.hidden_size, config.num_enc, bidirectional = self.bidirectional, batch_first=True) #config.num_layers\n        self.dropout = nn.Dropout(config.dropout)\n        \n    def forward(self, input):\n        output, hidden = self.algo(self.dropout(self.embedding(input)))\n        return output, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.697990Z","iopub.execute_input":"2025-05-19T07:04:54.698211Z","iopub.status.idle":"2025-05-19T07:04:54.711309Z","shell.execute_reply.started":"2025-05-19T07:04:54.698194Z","shell.execute_reply":"2025-05-19T07:04:54.710774Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, config, output_size):\n        super(DecoderRNN, self).__init__()\n\n        self.out = nn.Linear(config.hidden_size, output_size)\n        self.config = config\n        self.bidirectional = False\n           \n        self.embedding = nn.Embedding(output_size, config.hidden_size)\n        self.algo = algorithms[config.cell_type](config.hidden_size, config.hidden_size, config.num_enc, bidirectional = self.bidirectional, batch_first=True) #config.num_layers\n        self.out = nn.Linear(config.hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOW_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = F.relu(self.embedding(input))\n        output, hidden = self.algo(output, hidden)\n        output = self.out(output)\n        return output, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.712249Z","iopub.execute_input":"2025-05-19T07:04:54.712457Z","iopub.status.idle":"2025-05-19T07:04:54.726997Z","shell.execute_reply.started":"2025-05-19T07:04:54.712432Z","shell.execute_reply":"2025-05-19T07:04:54.726309Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n                decoder_optimizer, criterion, batch_size, teacher_forcing=True):\n\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for data in dataloader:\n        input_tensor, target_tensor = data  # shape: (B, MAX_LENGTH)\n        current_batch_size = input_tensor.size(0)\n\n        target_tensor2 = target_tensor if teacher_forcing else None\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor2)\n\n        outputs = decoder_outputs.view(-1, decoder_outputs.size(-1))  # shape: (B*MAX_LENGTH, vocab_size)\n        labels = target_tensor.view(-1)  # shape: (B*MAX_LENGTH)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)  # shape: (B*MAX_LENGTH)\n\n        # Accuracy: Count how many complete sequences match\n        predicted = predicted.view(current_batch_size, MAX_LENGTH)\n        labels = labels.view(current_batch_size, MAX_LENGTH)\n\n        matches = (predicted == labels).all(dim=1)  # shape: (B,)\n        correct += matches.sum().item()\n        total += current_batch_size\n\n    # print(correct)\n\n    return total_loss / len(dataloader), (correct*100) / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.727728Z","iopub.execute_input":"2025-05-19T07:04:54.727919Z","iopub.status.idle":"2025-05-19T07:04:54.738067Z","shell.execute_reply.started":"2025-05-19T07:04:54.727904Z","shell.execute_reply":"2025-05-19T07:04:54.737603Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train(train_dataloader, val_dataloader, test_dataloader, encoder, decoder, n_epochs, config):\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=config.lr)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=config.lr)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        print(\"Epoch:\",epoch)\n        loss, acc = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size)\n        print(\"Train: accuracy:\", acc, \"loss:\", loss)\n        if(acc<0.01 and epoch>=15):\n            break\n        val_loss, val_acc = train_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size, teacher_forcing=False)\n        print(\"Validation: accuracy:\", val_acc, \"Loss:\", val_loss)\n        wandb.log({'train_accuracy': acc,'train_loss': loss,'val_accuracy': val_acc,'val_loss': val_loss})\n        \n    test_loss, test_acc = train_epoch(test_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, config.batch_size, teacher_forcing=False)\n    print(\"Test: accuracy:\", test_acc, \"Loss:\", test_loss, \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.738706Z","iopub.execute_input":"2025-05-19T07:04:54.738876Z","iopub.status.idle":"2025-05-19T07:04:54.749388Z","shell.execute_reply.started":"2025-05-19T07:04:54.738860Z","shell.execute_reply":"2025-05-19T07:04:54.748890Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_epochs = 20\n\nalgorithms = {'rnn': nn.RNN,'gru': nn.GRU,'lstm': nn.LSTM}\n\nsweep_config = {\n    'method': 'bayes', \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'inp_embed_size':{\n            'values': [64, 128, 256]\n        },\n        'num_dec': {\n            'values': [1, 2, 3]\n        },\n        'num_enc': {\n            'values': [1, 2, 3]\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'lr': {\n            'values': [0.001, 0.0001]\n        },\n        'hidden_size': {\n            'values': [256]\n        },\n        'batch_size': {\n            'values': [64, 128, 256]\n        },\n        'cell_type':{\n            'values': ['rnn', 'gru']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='DL_A3')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:43:39.134887Z","iopub.execute_input":"2025-05-19T07:43:39.135573Z","iopub.status.idle":"2025-05-19T07:43:39.410965Z","shell.execute_reply.started":"2025-05-19T07:43:39.135530Z","shell.execute_reply":"2025-05-19T07:43:39.410403Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: mtcfnqzi\nSweep URL: https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def test():\n    with wandb.init() as run:\n        config = wandb.config\n\n        # Run name formatting\n        wandb.run.name = (\n            f\"{config.cell_type}-E_{config.num_enc}-D_{config.num_enc}-\"\n            f\"do_{config.dropout}-bs_{config.batch_size}-lr_{config.lr}-\"\n            f\"hs_{config.hidden_size}-emb_{config.inp_embed_size}-\")\n        \n        train_dataloader = get_dataloader(x_train, input_lang, output_lang, wandb.config.batch_size)\n        val_dataloader = get_dataloader(x_val, input_lang, output_lang, wandb.config.batch_size)\n        test_dataloader = get_dataloader(x_test, input_lang, output_lang, wandb.config.batch_size)\n        encoder = EncoderRNN(wandb.config, input_lang.n_letters).to(device)\n        decoder = DecoderRNN(wandb.config, output_lang.n_letters).to(device)\n        print(input_lang.n_letters, output_lang.n_letters)\n        train(train_dataloader, val_dataloader, test_dataloader, encoder, decoder, num_epochs, wandb.config)\n        # encoder.eval()\n        # decoder.eval()\n        # evaluate(encoder, decoder)\n        \nwandb.agent(sweep_id, function=test) # calls main function for count number of times. , count=1\nwandb.finish() #cojvqj9b sweep_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:43:51.571439Z","iopub.execute_input":"2025-05-19T07:43:51.572002Z","iopub.status.idle":"2025-05-19T09:08:11.646486Z","shell.execute_reply.started":"2025-05-19T07:43:51.571978Z","shell.execute_reply":"2025-05-19T09:08:11.645830Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hqyg7s31 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_074358-hqyg7s31</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/hqyg7s31' target=\"_blank\">leafy-sweep-1</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/hqyg7s31' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/hqyg7s31</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0 loss: 0.6650956464035749\nValidation: accuracy: 0.0 Loss: 0.8682441028316369\nEpoch: 2\nTrain: accuracy: 0.0 loss: 0.4951935721579674\nValidation: accuracy: 0.0 Loss: 0.8517633643043175\nEpoch: 3\nTrain: accuracy: 0.0 loss: 0.45797463295101987\nValidation: accuracy: 0.0 Loss: 0.8904221486509516\nEpoch: 4\nTrain: accuracy: 0.0 loss: 0.44154970052469467\nValidation: accuracy: 0.0 Loss: 0.8434952530968055\nEpoch: 5\nTrain: accuracy: 0.0 loss: 0.4273442731433735\nValidation: accuracy: 0.0 Loss: 0.8179512854372517\nEpoch: 6\nTrain: accuracy: 0.0 loss: 0.4132558388425382\nValidation: accuracy: 0.0 Loss: 0.8220115685730838\nEpoch: 7\nTrain: accuracy: 0.0 loss: 0.40286203755345296\nValidation: accuracy: 0.0 Loss: 0.8130715241592922\nEpoch: 8\nTrain: accuracy: 0.0 loss: 0.3937718674034566\nValidation: accuracy: 0.0 Loss: 0.8098514347933652\nEpoch: 9\nTrain: accuracy: 0.0017128567024082765 loss: 0.3841278578143522\nValidation: accuracy: 0.0 Loss: 0.8076106905937195\nEpoch: 10\nTrain: accuracy: 0.0017128567024082765 loss: 0.37523796867175274\nValidation: accuracy: 0.0 Loss: 0.7968095614669028\nEpoch: 11\nTrain: accuracy: 0.0 loss: 0.36807980529580425\nValidation: accuracy: 0.0 Loss: 0.8149770163418202\nEpoch: 12\nTrain: accuracy: 0.0 loss: 0.360958257451376\nValidation: accuracy: 0.0 Loss: 0.8201400168826071\nEpoch: 13\nTrain: accuracy: 0.0 loss: 0.3554371056786503\nValidation: accuracy: 0.0 Loss: 0.8107909372683322\nEpoch: 14\nTrain: accuracy: 0.0017128567024082765 loss: 0.3484015958659098\nValidation: accuracy: 0.0 Loss: 0.7926880014076662\nEpoch: 15\nTrain: accuracy: 0.0 loss: 0.34175802422901624\nTest: accuracy: 0.0 Loss: 0.8477745340629057 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁██▁▁▁█</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▆▅█▅▃▃▂▂▂▁▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.00171</td></tr><tr><td>train_loss</td><td>0.3484</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.79269</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rnn-E_3-D_3-do_0.3-bs_64-lr_0.0001-hs_256-emb_128-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/hqyg7s31' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/hqyg7s31</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_074358-hqyg7s31/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7tdam4lu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_075948-7tdam4lu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/7tdam4lu' target=\"_blank\">wandering-sweep-2</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/7tdam4lu' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/7tdam4lu</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0017128567024082765 loss: 0.8158819832608788\nValidation: accuracy: 0.0 Loss: 0.8730654610527886\nEpoch: 2\nTrain: accuracy: 0.0017128567024082765 loss: 0.5451947434334578\nValidation: accuracy: 0.0 Loss: 0.9183282163408067\nEpoch: 3\nTrain: accuracy: 0.0 loss: 0.4971040019712511\nValidation: accuracy: 0.0 Loss: 0.8193305664592319\nEpoch: 4\nTrain: accuracy: 0.0 loss: 0.45689975145870015\nValidation: accuracy: 0.01772735330615139 Loss: 0.7799878597259522\nEpoch: 5\nTrain: accuracy: 0.0 loss: 0.42491134009945575\nValidation: accuracy: 0.01772735330615139 Loss: 0.7434302753872342\nEpoch: 6\nTrain: accuracy: 0.008564283512041382 loss: 0.39874835628649336\nValidation: accuracy: 0.10636411983690836 Loss: 0.7155773255560133\nEpoch: 7\nTrain: accuracy: 0.056524271179473125 loss: 0.3741072825842926\nValidation: accuracy: 0.10636411983690836 Loss: 0.6922286947568258\nEpoch: 8\nTrain: accuracy: 0.11476139906135453 loss: 0.35042334946292236\nValidation: accuracy: 0.12409147314305974 Loss: 0.6737480885452695\nEpoch: 9\nTrain: accuracy: 0.20040423418176836 loss: 0.3284641557762346\nValidation: accuracy: 0.12409147314305974 Loss: 0.6538310209910075\nEpoch: 10\nTrain: accuracy: 0.31345277654071463 loss: 0.30827132826039255\nValidation: accuracy: 0.12409147314305974 Loss: 0.6529491331842211\nEpoch: 11\nTrain: accuracy: 0.48816416018635883 loss: 0.2911071909073928\nValidation: accuracy: 0.24818294628611948 Loss: 0.6420112782054477\nEpoch: 12\nTrain: accuracy: 0.6954198211777602 loss: 0.27535531759522935\nValidation: accuracy: 0.15954617975536253 Loss: 0.63470991452535\nEpoch: 13\nTrain: accuracy: 1.046555445171457 loss: 0.26201230434281036\nValidation: accuracy: 0.24818294628611948 Loss: 0.626450334654914\nEpoch: 14\nTrain: accuracy: 1.3908396423555205 loss: 0.24991784168150544\nValidation: accuracy: 0.4431838326537848 Loss: 0.6102902630964915\nEpoch: 15\nTrain: accuracy: 1.846459525196122 loss: 0.23867492863594572\nValidation: accuracy: 0.35454706612302783 Loss: 0.6020979583263397\nEpoch: 16\nTrain: accuracy: 2.2900894111198657 loss: 0.2285261350791877\nValidation: accuracy: 0.6204573657152987 Loss: 0.5864412811067369\nEpoch: 17\nTrain: accuracy: 2.910143537391662 loss: 0.2182756606937759\nValidation: accuracy: 0.47863853926608757 Loss: 0.5796399480766721\nEpoch: 18\nTrain: accuracy: 3.574731937926073 loss: 0.2095091630189111\nValidation: accuracy: 0.815458252082964 Loss: 0.5668727808528476\nEpoch: 19\nTrain: accuracy: 4.360933164331472 loss: 0.20060259946652523\nValidation: accuracy: 0.726821485552207 Loss: 0.5661733587582906\nEpoch: 20\nTrain: accuracy: 5.2875886403343495 loss: 0.1936853147179084\nValidation: accuracy: 1.081368551675235 Loss: 0.5585383362240262\nTest: accuracy: 0.28520499108734404 Loss: 0.485914718021046 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▅▆▇█</td></tr><tr><td>train_loss</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▂▂▂▂▂▃▂▃▄▃▅▄▆▆█</td></tr><tr><td>val_loss</td><td>▇█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>5.28759</td></tr><tr><td>train_loss</td><td>0.19369</td></tr><tr><td>val_accuracy</td><td>1.08137</td></tr><tr><td>val_loss</td><td>0.55854</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gru-E_1-D_1-do_0.2-bs_128-lr_0.0001-hs_256-emb_256-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/7tdam4lu' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/7tdam4lu</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_075948-7tdam4lu/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6l8u3ubg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_080948-6l8u3ubg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/6l8u3ubg' target=\"_blank\">honest-sweep-3</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/6l8u3ubg' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/6l8u3ubg</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0 loss: 0.7126096830114739\nValidation: accuracy: 0.03545470661230278 Loss: 0.7369306763906157\nEpoch: 2\nTrain: accuracy: 0.03425713404816553 loss: 0.45707524642103475\nValidation: accuracy: 0.12409147314305974 Loss: 0.5888795226477506\nEpoch: 3\nTrain: accuracy: 0.47274844986468434 loss: 0.3465876151345515\nValidation: accuracy: 0.7800035454706612 Loss: 0.528822761238291\nEpoch: 4\nTrain: accuracy: 1.7676681168853414 loss: 0.2676287122878684\nValidation: accuracy: 1.3472788512675058 Loss: 0.4778485345036796\nEpoch: 5\nTrain: accuracy: 4.861087321434689 loss: 0.20829999789611925\nValidation: accuracy: 2.605920936004255 Loss: 0.44291959418339677\nEpoch: 6\nTrain: accuracy: 9.751293206810319 loss: 0.1671705367319033\nValidation: accuracy: 4.502747739762453 Loss: 0.41137926933470736\nEpoch: 7\nTrain: accuracy: 15.674351683738138 loss: 0.13851519297045398\nValidation: accuracy: 6.63003013650062 Loss: 0.3841663578922829\nEpoch: 8\nTrain: accuracy: 21.354184508923982 loss: 0.11776117117094184\nValidation: accuracy: 8.065945754298884 Loss: 0.3605524947804012\nEpoch: 9\nTrain: accuracy: 26.89013737110753 loss: 0.10219514067208257\nValidation: accuracy: 11.07959581634462 Loss: 0.3390296639016505\nEpoch: 10\nTrain: accuracy: 31.641601863588093 loss: 0.08984539265716847\nValidation: accuracy: 13.667789399042723 Loss: 0.3214234502128001\nEpoch: 11\nTrain: accuracy: 36.033366448562916 loss: 0.08004169956845235\nValidation: accuracy: 17.603261833008332 Loss: 0.29754989912335794\nEpoch: 12\nTrain: accuracy: 39.996916857935666 loss: 0.07185781656928679\nValidation: accuracy: 19.35826981031732 Loss: 0.2851198819581042\nEpoch: 13\nTrain: accuracy: 43.85769586516392 loss: 0.06503420211741984\nValidation: accuracy: 23.116468711221415 Loss: 0.27273092544480654\nEpoch: 14\nTrain: accuracy: 46.90144222534343 loss: 0.059245482083055044\nValidation: accuracy: 25.048750221591916 Loss: 0.2529962198453003\nEpoch: 15\nTrain: accuracy: 49.97259429276147 loss: 0.05425069042504944\nValidation: accuracy: 28.41694734976068 Loss: 0.24328799981079743\nEpoch: 16\nTrain: accuracy: 52.70631358980508 loss: 0.05004096344962047\nValidation: accuracy: 31.926963304378656 Loss: 0.21866843137848244\nEpoch: 17\nTrain: accuracy: 55.251618649583776 loss: 0.04614907968075291\nValidation: accuracy: 35.241978372628964 Loss: 0.2116004503175114\nEpoch: 18\nTrain: accuracy: 57.75924086190949 loss: 0.042431115381917454\nValidation: accuracy: 37.24516929622408 Loss: 0.20385726306880458\nEpoch: 19\nTrain: accuracy: 59.94313315748005 loss: 0.03968426550515119\nValidation: accuracy: 40.96791349051587 Loss: 0.1912815369079622\nEpoch: 20\nTrain: accuracy: 62.33256825733959 loss: 0.0366764635904432\nValidation: accuracy: 41.872008509129586 Loss: 0.1854567194587729\nTest: accuracy: 35.258467023172905 Loss: 0.19030483964491973 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▂▂▃▃▄▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▂▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>62.33257</td></tr><tr><td>train_loss</td><td>0.03668</td></tr><tr><td>val_accuracy</td><td>41.87201</td></tr><tr><td>val_loss</td><td>0.18546</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gru-E_3-D_3-do_0.3-bs_64-lr_0.0001-hs_256-emb_64-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/6l8u3ubg' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/6l8u3ubg</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_080948-6l8u3ubg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5glch16f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_083929-5glch16f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/5glch16f' target=\"_blank\">breezy-sweep-4</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/5glch16f' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/5glch16f</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0 loss: 0.7739179126543342\nValidation: accuracy: 0.0 Loss: 0.9022456076410081\nEpoch: 2\nTrain: accuracy: 0.0 loss: 0.5510292909468811\nValidation: accuracy: 0.0 Loss: 0.9241186287668016\nEpoch: 3\nTrain: accuracy: 0.0 loss: 0.5073811334254184\nValidation: accuracy: 0.0 Loss: 0.9486446566051907\nEpoch: 4\nTrain: accuracy: 0.0 loss: 0.48347228374209916\nValidation: accuracy: 0.0 Loss: 1.0064421521292792\nEpoch: 5\nTrain: accuracy: 0.0 loss: 0.4787094315240889\nValidation: accuracy: 0.0 Loss: 0.8966968403922186\nEpoch: 6\nTrain: accuracy: 0.0 loss: 0.45873728564062055\nValidation: accuracy: 0.0 Loss: 0.9178169329961141\nEpoch: 7\nTrain: accuracy: 0.0 loss: 0.45034276917413757\nValidation: accuracy: 0.0 Loss: 0.9238175405396356\nEpoch: 8\nTrain: accuracy: 0.0 loss: 0.4419031405344573\nValidation: accuracy: 0.0 Loss: 0.9281988024711609\nEpoch: 9\nTrain: accuracy: 0.0 loss: 0.43491515497670913\nValidation: accuracy: 0.0 Loss: 0.8627900838851928\nEpoch: 10\nTrain: accuracy: 0.00513857010722483 loss: 0.4260969941934298\nValidation: accuracy: 0.0 Loss: 0.8792057951291402\nEpoch: 11\nTrain: accuracy: 0.011989996916857936 loss: 0.4206155992441156\nValidation: accuracy: 0.0 Loss: 0.8774510304133097\nEpoch: 12\nTrain: accuracy: 0.0017128567024082765 loss: 0.4158480498670749\nValidation: accuracy: 0.0 Loss: 0.8840634187062582\nEpoch: 13\nTrain: accuracy: 0.006851426809633106 loss: 0.4090311245532213\nValidation: accuracy: 0.0 Loss: 0.8902620222833422\nEpoch: 14\nTrain: accuracy: 0.003425713404816553 loss: 0.40730075450120923\nValidation: accuracy: 0.0 Loss: 0.8440843171543545\nEpoch: 15\nTrain: accuracy: 0.0017128567024082765 loss: 0.39613684379298003\nTest: accuracy: 0.0 Loss: 0.9200524714860049 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▄█▂▅▃</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▄▆█▃▄▄▅▂▃▂▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.00343</td></tr><tr><td>train_loss</td><td>0.4073</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.84408</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rnn-E_3-D_3-do_0.2-bs_128-lr_0.0001-hs_256-emb_64-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/5glch16f' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/5glch16f</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_083929-5glch16f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fjjvirb2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_085014-fjjvirb2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/fjjvirb2' target=\"_blank\">driven-sweep-5</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/fjjvirb2' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/fjjvirb2</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0 loss: 0.7692091762367432\nValidation: accuracy: 0.0 Loss: 0.8960955474111769\nEpoch: 2\nTrain: accuracy: 0.0 loss: 0.5537206602957369\nValidation: accuracy: 0.0 Loss: 0.9247069517771404\nEpoch: 3\nTrain: accuracy: 0.0 loss: 0.5089050406830576\nValidation: accuracy: 0.0 Loss: 0.9992077045970493\nEpoch: 4\nTrain: accuracy: 0.0 loss: 0.492232779248799\nValidation: accuracy: 0.0 Loss: 0.8654321047994825\nEpoch: 5\nTrain: accuracy: 0.0 loss: 0.471723957969532\nValidation: accuracy: 0.0 Loss: 0.8948398921224806\nEpoch: 6\nTrain: accuracy: 0.0 loss: 0.46002776845800536\nValidation: accuracy: 0.0 Loss: 0.964135558075375\nEpoch: 7\nTrain: accuracy: 0.00513857010722483 loss: 0.45094982278686124\nValidation: accuracy: 0.0 Loss: 0.8933986518118117\nEpoch: 8\nTrain: accuracy: 0.0017128567024082765 loss: 0.44035606017780515\nValidation: accuracy: 0.0 Loss: 0.9123984098434448\nEpoch: 9\nTrain: accuracy: 0.0 loss: 0.43206893810818964\nValidation: accuracy: 0.0 Loss: 0.8997966355747646\nEpoch: 10\nTrain: accuracy: 0.0 loss: 0.4271829553453875\nValidation: accuracy: 0.0 Loss: 0.8672042224142287\nEpoch: 11\nTrain: accuracy: 0.0 loss: 0.41703464465798645\nValidation: accuracy: 0.0 Loss: 0.8606461644172668\nEpoch: 12\nTrain: accuracy: 0.0 loss: 0.415023269747227\nValidation: accuracy: 0.0 Loss: 0.8605234954092238\nEpoch: 13\nTrain: accuracy: 0.0 loss: 0.4065733210263158\nValidation: accuracy: 0.0 Loss: 0.9007297886742486\nEpoch: 14\nTrain: accuracy: 0.0017128567024082765 loss: 0.4073677212325958\nValidation: accuracy: 0.0 Loss: 0.8549510280291239\nEpoch: 15\nTrain: accuracy: 0.0 loss: 0.39530110326585416\nTest: accuracy: 0.0 Loss: 0.8608408881859346 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁█▃▁▁▁▁▁▃</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▃▄█▂▃▆▃▄▃▂▁▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.00171</td></tr><tr><td>train_loss</td><td>0.40737</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.85495</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rnn-E_3-D_3-do_0.3-bs_128-lr_0.0001-hs_256-emb_128-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/fjjvirb2' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/fjjvirb2</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_085014-fjjvirb2/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ghw4uggg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_090058-ghw4uggg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/ghw4uggg' target=\"_blank\">young-sweep-6</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/mtcfnqzi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/ghw4uggg' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/ghw4uggg</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.0 loss: 0.9771175837412672\nValidation: accuracy: 0.0 Loss: 0.8357292646947114\nEpoch: 2\nTrain: accuracy: 0.0 loss: 0.6409975852508212\nValidation: accuracy: 0.0 Loss: 0.8738661278849063\nEpoch: 3\nTrain: accuracy: 0.0 loss: 0.5769263628268346\nValidation: accuracy: 0.0 Loss: 0.8817227379135464\nEpoch: 4\nTrain: accuracy: 0.0 loss: 0.529188605375165\nValidation: accuracy: 0.0 Loss: 0.7942237076552018\nEpoch: 5\nTrain: accuracy: 0.013702853619266212 loss: 0.47011234887822745\nValidation: accuracy: 0.03545470661230278 Loss: 0.6820898652076721\nEpoch: 6\nTrain: accuracy: 0.10619711554931315 loss: 0.4112136544879347\nValidation: accuracy: 0.407729126041482 Loss: 0.6293107621047808\nEpoch: 7\nTrain: accuracy: 0.3066013497310815 loss: 0.3648667776688738\nValidation: accuracy: 0.7622761921645098 Loss: 0.617484564366548\nEpoch: 8\nTrain: accuracy: 0.6680141139392278 loss: 0.32764819407567186\nValidation: accuracy: 1.0990959049813862 Loss: 0.5738127944262131\nEpoch: 9\nTrain: accuracy: 1.2623753896748997 loss: 0.29497620398300706\nValidation: accuracy: 1.7550079773089877 Loss: 0.569701867259067\nEpoch: 10\nTrain: accuracy: 2.0382994758658493 loss: 0.266652620905872\nValidation: accuracy: 2.2868285764935297 Loss: 0.5362754295701566\nEpoch: 11\nTrain: accuracy: 3.148230619026412 loss: 0.24184063714664575\nValidation: accuracy: 3.2263783017195533 Loss: 0.5083889702092046\nEpoch: 12\nTrain: accuracy: 4.56133739851324 loss: 0.21974071424340577\nValidation: accuracy: 4.360928913313242 Loss: 0.49500502322031104\nEpoch: 13\nTrain: accuracy: 6.323866945291357 loss: 0.20130817683242813\nValidation: accuracy: 5.282751285233115 Loss: 0.4880574501079062\nEpoch: 14\nTrain: accuracy: 8.2782364427392 loss: 0.18504453694456008\nValidation: accuracy: 6.7186669030313775 Loss: 0.4648355517698371\nEpoch: 15\nTrain: accuracy: 10.268575930937617 loss: 0.17059432881107497\nValidation: accuracy: 8.29640134727885 Loss: 0.4480825766273167\nEpoch: 16\nTrain: accuracy: 12.735089582405536 loss: 0.15848118554817017\nValidation: accuracy: 9.023222832831058 Loss: 0.44335170284561487\nEpoch: 17\nTrain: accuracy: 14.975506149155562 loss: 0.14817689957837352\nValidation: accuracy: 10.494593157241624 Loss: 0.41875573992729187\nEpoch: 18\nTrain: accuracy: 17.118289883868314 loss: 0.13876710213948545\nValidation: accuracy: 12.054600248182947 Loss: 0.409211577280708\nEpoch: 19\nTrain: accuracy: 19.307320749546093 loss: 0.13033653122238717\nValidation: accuracy: 13.720971458961177 Loss: 0.3900616933470187\nEpoch: 20\nTrain: accuracy: 21.542598746188894 loss: 0.12293429841901538\nValidation: accuracy: 15.2809785499025 Loss: 0.37996617089147156\nTest: accuracy: 8.03921568627451 Loss: 0.3530727651986209 \n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▄▅▅▆▇▇█</td></tr><tr><td>val_loss</td><td>▇██▇▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>21.5426</td></tr><tr><td>train_loss</td><td>0.12293</td></tr><tr><td>val_accuracy</td><td>15.28098</td></tr><tr><td>val_loss</td><td>0.37997</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gru-E_2-D_2-do_0.3-bs_256-lr_0.0001-hs_256-emb_128-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/ghw4uggg' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/ghw4uggg</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_090058-ghw4uggg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def evaluate_and_save_predictions(encoder, decoder):\n    results = []\n    correct_preds = []\n    incorrect_preds = []\n    output_file = 'test_predictions.tsv'\n    table = PrettyTable()\n    table.field_names = [\"Sample #\", \"Input\", \"Ground Truth\", \"Prediction\", \"Correct?\"]\n\n    with torch.no_grad():\n        for i in range(len(x_test[0])):\n            input_seq = x_test[1][i]\n            true_output = x_test[0][i]\n\n            input_tensor = tensorFromWord(input_lang, input_seq)\n            encoder_outputs, encoder_hidden = encoder(input_tensor)\n            decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n            _, topi = decoder_outputs.topk(1)\n            decoded_ids = topi.squeeze()\n\n            predicted_output = ''\n            for idx in decoded_ids:\n                if idx.item() == EOW_token:\n                    break\n                predicted_output += output_lang.index2letter.get(idx.item(), '?')\n\n            results.append((input_seq, true_output, predicted_output))\n\n            if predicted_output == true_output:\n                correct_preds.append((input_seq, true_output, predicted_output))\n            else:\n                incorrect_preds.append((input_seq, true_output, predicted_output))\n\n    # Randomly sample 10 from each category\n    sample_correct = random.sample(correct_preds, min(10, len(correct_preds)))\n    sample_incorrect = random.sample(incorrect_preds, min(10, len(incorrect_preds)))\n\n    # Add rows to table\n    for i, (inp, true, pred) in enumerate(sample_correct + sample_incorrect):\n        table.add_row([\n            i + 1,\n            inp,\n            true,\n            pred,\n            \"✅\" if pred == true else \"❌\"\n        ])\n\n    # Print table\n    print(\"\\n📊 Sample Predictions (10 Correct + 10 Incorrect):\\n\")\n    print(table)\n\n    # Save all predictions as TSV with UTF-8 encoding\n    df = pd.DataFrame(results, columns=[\"Input\", \"Ground Truth\", \"Prediction\"])\n    df.to_csv(output_file, index=False, sep='\\t', encoding='utf-8-sig')\n    print(f\"\\n📁 All test predictions saved to: {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.793269Z","iopub.execute_input":"2025-05-19T07:04:54.793488Z","iopub.status.idle":"2025-05-19T07:04:54.807592Z","shell.execute_reply.started":"2025-05-19T07:04:54.793469Z","shell.execute_reply":"2025-05-19T07:04:54.806941Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Best Model\nnum_epochs = 20\n\nalgorithms = {'rnn': nn.RNN,'gru': nn.GRU,'lstm': nn.LSTM}\n\nbest_config = {\n    'method': 'bayes', \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'inp_embed_size':{\n            'values': [256]\n        },\n        'num_dec': {\n            'values': [3]\n        },\n        'num_enc': {\n            'values': [3]\n        },\n        'dropout': {\n            'values': [0.3]\n        },\n        'lr': {\n            'values': [0.001]\n        },\n        'hidden_size': {\n            'values': [256]\n        },\n        'batch_size': {\n            'values': [64]\n        },\n        'cell_type':{\n            'values': ['lstm']\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep=best_config, project='DL_A3')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:54.808235Z","iopub.execute_input":"2025-05-19T07:04:54.808502Z","iopub.status.idle":"2025-05-19T07:04:55.058851Z","shell.execute_reply.started":"2025-05-19T07:04:54.808482Z","shell.execute_reply":"2025-05-19T07:04:55.058106Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ga83y5dh\nSweep URL: https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/ga83y5dh\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def test():\n    with wandb.init() as run:\n        config = wandb.config\n\n        # Run name formatting\n        wandb.run.name = (\n            f\"{config.cell_type}-E_{config.num_enc}-D_{config.num_enc}-\"\n            f\"do_{config.dropout}-bs_{config.batch_size}-lr_{config.lr}-\"\n            f\"hs_{config.hidden_size}-emb_{config.inp_embed_size}-\")\n        \n        train_dataloader = get_dataloader(x_train, input_lang, output_lang, wandb.config.batch_size)\n        val_dataloader = get_dataloader(x_val, input_lang, output_lang, wandb.config.batch_size)\n        test_dataloader = get_dataloader(x_test, input_lang, output_lang, wandb.config.batch_size)\n        encoder = EncoderRNN(wandb.config, input_lang.n_letters).to(device)\n        decoder = DecoderRNN(wandb.config, output_lang.n_letters).to(device)\n        print(input_lang.n_letters, output_lang.n_letters)\n        train(train_dataloader, val_dataloader, test_dataloader, encoder, decoder, num_epochs, wandb.config)\n        encoder.eval()\n        decoder.eval()\n        evaluate_and_save_predictions(encoder, decoder)\n        \nwandb.agent(sweep_id, function=test, count=1) # calls main function for count number of times. , count=1\nwandb.finish() #cojvqj9b sweep_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T07:04:55.059647Z","iopub.execute_input":"2025-05-19T07:04:55.059903Z","iopub.status.idle":"2025-05-19T07:40:06.231729Z","shell.execute_reply.started":"2025-05-19T07:04:55.059882Z","shell.execute_reply":"2025-05-19T07:40:06.231008Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: czdklr55 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinp_embed_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_070501-czdklr55</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/czdklr55' target=\"_blank\">rural-sweep-1</a></strong> to <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/ga83y5dh' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/ga83y5dh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/ga83y5dh' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/sweeps/ga83y5dh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/czdklr55' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/czdklr55</a>"},"metadata":{}},{"name":"stdout","text":"28 72\nEpoch: 1\nTrain: accuracy: 0.006851426809633106 loss: 0.5371539197119538\nValidation: accuracy: 0.01772735330615139 Loss: 0.5985575479068114\nEpoch: 2\nTrain: accuracy: 6.731526840464527 loss: 0.22551415269013173\nValidation: accuracy: 5.495479524906932 Loss: 0.3696252606557996\nEpoch: 3\nTrain: accuracy: 27.90586139563564 loss: 0.10346452793083995\nValidation: accuracy: 15.511434142882468 Loss: 0.2913090188181802\nEpoch: 4\nTrain: accuracy: 41.58130930766332 loss: 0.06927306238900531\nValidation: accuracy: 24.8360219819181 Loss: 0.24873447635870302\nEpoch: 5\nTrain: accuracy: 51.16988112774485 loss: 0.05186797272483334\nValidation: accuracy: 30.384683566743487 Loss: 0.2210860520266415\nEpoch: 6\nTrain: accuracy: 58.362166421157205 loss: 0.04085318874751359\nValidation: accuracy: 38.8406310937777 Loss: 0.18889590143487694\nEpoch: 7\nTrain: accuracy: 63.81418930492275 loss: 0.03344602544607364\nValidation: accuracy: 45.346569757135256 Loss: 0.17045104059945332\nEpoch: 8\nTrain: accuracy: 68.84313658319346 loss: 0.02738647859825101\nValidation: accuracy: 51.994327246942035 Loss: 0.1462701673336913\nEpoch: 9\nTrain: accuracy: 72.06330718372101 loss: 0.02341544628347324\nValidation: accuracy: 55.646162028009215 Loss: 0.13050996219174246\nEpoch: 10\nTrain: accuracy: 75.37939775958343 loss: 0.019710452685505968\nValidation: accuracy: 61.40755185250842 Loss: 0.11284573150149892\nEpoch: 11\nTrain: accuracy: 78.08057277928128 loss: 0.017181925410312996\nValidation: accuracy: 64.81120368728949 Loss: 0.10074217675065392\nEpoch: 12\nTrain: accuracy: 80.07433798088452 loss: 0.01512061545894627\nValidation: accuracy: 69.84577202623649 Loss: 0.0901600444124321\nEpoch: 13\nTrain: accuracy: 81.20311054777157 loss: 0.013977750842046372\nValidation: accuracy: 72.27441942917922 Loss: 0.08273465512843614\nEpoch: 14\nTrain: accuracy: 82.698434448974 loss: 0.012641495034539294\nValidation: accuracy: 75.50079773089878 Loss: 0.07283703018021717\nEpoch: 15\nTrain: accuracy: 83.81007844883698 loss: 0.011561640787682\nValidation: accuracy: 75.50079773089878 Loss: 0.07203130894916111\nEpoch: 16\nTrain: accuracy: 84.90288102497345 loss: 0.010591323260495363\nValidation: accuracy: 79.06399574543521 Loss: 0.06087297150927983\nEpoch: 17\nTrain: accuracy: 85.2231852283238 loss: 0.010216839022185707\nValidation: accuracy: 81.26218755539797 Loss: 0.053813887236828215\nEpoch: 18\nTrain: accuracy: 86.41190777979514 loss: 0.009240099185310623\nValidation: accuracy: 82.21946463393016 Loss: 0.051969279137471416\nEpoch: 19\nTrain: accuracy: 86.70480627590696 loss: 0.009087219232742277\nValidation: accuracy: 82.71583052650239 Loss: 0.05105642204204302\nEpoch: 20\nTrain: accuracy: 87.0456647596862 loss: 0.008584333895598532\nValidation: accuracy: 83.63765289842226 Loss: 0.04787665582523587\nTest: accuracy: 49.590017825311946 Loss: 0.1591757224364714 \n\n\n📊 Sample Predictions (10 Correct + 10 Incorrect):\n\n+----------+---------------------+--------------+----------------------------------------------------+----------+\n| Sample # |        Input        | Ground Truth |                     Prediction                     | Correct? |\n+----------+---------------------+--------------+----------------------------------------------------+----------+\n|    1     |   janasamoohathil   |   ജനസമൂഹത്തിൽ   |                      ജനസമൂഹത്തിൽ                      |    ✅    |\n|    2     |     kaduppamulla    |   കടുപ്പമുള്ള    |                      കടുപ്പമുള്ള                       |    ✅    |\n|    3     |    aoudaaryathil    |   ഔദാര്യത്തിൽ    |                      ഔദാര്യത്തിൽ                       |    ✅    |\n|    4     |    shreenivaasan    |    ശ്രീനിവാസൻ    |                       ശ്രീനിവാസൻ                       |    ✅    |\n|    5     |   mukhyamantriyayi  |  മുഖ്യമന്ത്രിയായി   |                     മുഖ്യമന്ത്രിയായി                      |    ✅    |\n|    6     |   stediyathilaanu   |  സ്റ്റേഡിയത്തിലാണ്   |                     സ്റ്റേഡിയത്തിലാണ്                      |    ✅    |\n|    7     |     kaattilekku     |    കാട്ടിലേക്ക്    |                       കാട്ടിലേക്ക്                       |    ✅    |\n|    8     |     amgathvavum     |    അംഗത്വവും     |                       അംഗത്വവും                        |    ✅    |\n|    9     | dhakshinaafrikkayil |  ദക്ഷിണാഫ്രിക്കയിൽ  |                     ദക്ഷിണാഫ്രിക്കയിൽ                     |    ✅    |\n|    10    |   samaramaayirunnu  |   സമരമായിരുന്നു   |                      സമരമായിരുന്നു                      |    ✅    |\n|    11    |        aandi        |     ആൻഡി      |                         ബ്ധി                         |    ❌    |\n|    12    |     jayashankar     |    ജയശങ്കർ    |                       ജയശ്്കൾ                        |    ❌    |\n|    13    |        rodile       |     റോഡിലെ      |                        റൈയിൽ                         |    ❌    |\n|    14    |        gypsum       |     ജിപ്സം      |                         ജ്പീും                         |    ❌    |\n|    15    |        muslim       |     മുസ്‌ലിം      |                        മ്സിലും                         |    ❌    |\n|    16    |     lokabankinte    |   ലോകബാങ്കിന്റെ    |                       ലോകമണ്്ിി്റ0                       |    ❌    |\n|    17    |     mungaamikal     |    മുൻഗാമികൾ    |                       മുഖാനികൾ                        |    ❌    |\n|    18    |    vivaranathinte   |   വിവരണത്തിന്റെ   |                      വിരരത്തിന്റെ                       |    ❌    |\n|    19    |       billian       |     ബില്യൺ     |                        ബിയ്യൻ                        |    ❌    |\n|    20    |         sera        |      സെറ      | സ0000000000000000000000000000000000000000000000000 |    ❌    |\n+----------+---------------------+--------------+----------------------------------------------------+----------+\n\n📁 All test predictions saved to: test_predictions.tsv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▂▃▄▅▆▆▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▃▄▄▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>87.04566</td></tr><tr><td>train_loss</td><td>0.00858</td></tr><tr><td>val_accuracy</td><td>83.63765</td></tr><tr><td>val_loss</td><td>0.04788</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lstm-E_3-D_3-do_0.3-bs_64-lr_0.001-hs_256-emb_256-</strong> at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/czdklr55' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3/runs/czdklr55</a><br> View project at: <a href='https://wandb.ai/alandandoor-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/alandandoor-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_070501-czdklr55/logs</code>"},"metadata":{}}],"execution_count":14}]}